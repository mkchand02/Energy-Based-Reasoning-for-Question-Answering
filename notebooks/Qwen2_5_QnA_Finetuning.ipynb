{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 14058650,
          "sourceType": "datasetVersion",
          "datasetId": 8948133
        }
      ],
      "dockerImageVersionId": 31192,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Qwen2.5_QnA_Finetuning.ipynb\n",
        "This notebook is designed to fine-tune a pre-trained Qwen language model for a question-answering task using the Physics StackExchange dataset. It then evaluates the fine-tuned model's performance using perplexity, BLEU, and ROUGE metrics, and visualizes the results."
      ],
      "metadata": {
        "id": "l2I7t2m_9hdy"
      },
      "id": "l2I7t2m_9hdy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup and Data Loading"
      ],
      "metadata": {
        "id": "l7reCuaQ9qNL"
      },
      "id": "l7reCuaQ9qNL"
    },
    {
      "id": "c9de08d7-3c32-43e4-b273-2e559239ef9d",
      "cell_type": "code",
      "source": [
        "# !pip install -U \"huggingface_hub[cli]\" # Ensure CLI is installed\n",
        "# !huggingface-cli scan-cache"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-08T18:04:29.726195Z",
          "iopub.execute_input": "2025-12-08T18:04:29.727097Z",
          "iopub.status.idle": "2025-12-08T18:04:29.730642Z",
          "shell.execute_reply.started": "2025-12-08T18:04:29.727077Z",
          "shell.execute_reply": "2025-12-08T18:04:29.729990Z"
        },
        "id": "c9de08d7-3c32-43e4-b273-2e559239ef9d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "920ec75e-d147-4588-8191-e08fde9eb054",
      "cell_type": "code",
      "source": [
        "# !huggingface-cli delete-cache"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-08T18:04:29.731338Z",
          "iopub.execute_input": "2025-12-08T18:04:29.731513Z",
          "iopub.status.idle": "2025-12-08T18:04:29.743189Z",
          "shell.execute_reply.started": "2025-12-08T18:04:29.731498Z",
          "shell.execute_reply": "2025-12-08T18:04:29.742432Z"
        },
        "id": "920ec75e-d147-4588-8191-e08fde9eb054"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a13f4d22-6d80-41da-8182-13254cfbd385",
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 0. Imports\n",
        "# ---------------------------\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "PATH = \"/kaggle/input/physics-stackexchange/\"\n",
        "import wandb\n",
        "wandb.login(key = \"8167d8f0f429b191c4958866ae4a9ef380ae62ef\")\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "\n",
        "# Initialize W&B\n",
        "\n",
        "wandb.init(project=\"QuestionAnsweringProject\", name=\"qwen_finetune\")\n",
        "\n",
        "\n",
        "# Device check\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "\n",
        "# Load dataset (parquet files)\n",
        "train_df = pd.read_parquet(PATH + \"physics_baseline_train.parquet\")\n",
        "valid_df = pd.read_parquet(PATH + \"physics_baseline_valid.parquet\")\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_df)\n",
        "valid_ds = Dataset.from_pandas(valid_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-08T18:04:29.744056Z",
          "iopub.execute_input": "2025-12-08T18:04:29.744303Z",
          "iopub.status.idle": "2025-12-08T18:04:56.698834Z",
          "shell.execute_reply.started": "2025-12-08T18:04:29.744280Z",
          "shell.execute_reply": "2025-12-08T18:04:56.698173Z"
        },
        "id": "a13f4d22-6d80-41da-8182-13254cfbd385",
        "outputId": "918984dc-df40-422c-cc0c-99abe53a01b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmc77chand\u001b[0m (\u001b[33mmc77chand-stevens-institute-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n2025-12-08 18:04:44.947655: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765217084.971131     184 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765217084.978171     184 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.21.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20251208_180449-lmvsr3f0</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/mc77chand-stevens-institute-of-technology/QuestionAnsweringProject/runs/lmvsr3f0' target=\"_blank\">qwen_finetune</a></strong> to <a href='https://wandb.ai/mc77chand-stevens-institute-of-technology/QuestionAnsweringProject' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/mc77chand-stevens-institute-of-technology/QuestionAnsweringProject' target=\"_blank\">https://wandb.ai/mc77chand-stevens-institute-of-technology/QuestionAnsweringProject</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/mc77chand-stevens-institute-of-technology/QuestionAnsweringProject/runs/lmvsr3f0' target=\"_blank\">https://wandb.ai/mc77chand-stevens-institute-of-technology/QuestionAnsweringProject/runs/lmvsr3f0</a>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Using device: cuda\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "id": "54b6661b-39c3-4a5e-93a8-6ebb96f9169b",
      "cell_type": "code",
      "source": [
        "from transformers import TrainerCallback\n",
        "import wandb\n",
        "import os, shutil\n",
        "\n",
        "class WandbLimitedCheckpointCallback(TrainerCallback):\n",
        "    \"\"\"\n",
        "    This class defines a custom WandbLimitedCheckpointCallback class.\n",
        "    This callback is used during model training to manage checkpoints.\n",
        "    It saves model checkpoints as W&B artifacts and limits the number of\n",
        "    saved checkpoints on disk to keep_last (in this case, 2), deleting older ones to free up space.\n",
        "    \"\"\"\n",
        "    def __init__(self, project=\"my-llm-project\", keep_last=2):\n",
        "        self.project = project\n",
        "        self.keep_last = keep_last\n",
        "        self.saved_artifacts = []\n",
        "\n",
        "    def on_save(self, args, state, control, **kwargs):\n",
        "        checkpoint_dir = os.path.join(args.output_dir, f\"checkpoint-{state.global_step}\")\n",
        "        if os.path.exists(checkpoint_dir):\n",
        "            if wandb.run is not None:\n",
        "                artifact = wandb.Artifact(\n",
        "                    name=f\"qwen-checkpoint-{state.global_step}\",\n",
        "                    type=\"model\",\n",
        "                    description=f\"Checkpoint at step {state.global_step}\"\n",
        "                    )\n",
        "                artifact.add_dir(checkpoint_dir)\n",
        "                wandb.log_artifact(artifact)\n",
        "\n",
        "            self.saved_artifacts.append((state.global_step, checkpoint_dir))\n",
        "\n",
        "            # If we have more than N checkpoints, delete oldest\n",
        "            if len(self.saved_artifacts) > self.keep_last:\n",
        "                old_step, old_dir = self.saved_artifacts.pop(0)\n",
        "                if os.path.exists(old_dir):\n",
        "                    shutil.rmtree(old_dir)   # free Kaggle space\n",
        "                # Optionally: you could also delete older W&B artifacts manually if neede"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-08T18:04:56.699627Z",
          "iopub.execute_input": "2025-12-08T18:04:56.699916Z",
          "iopub.status.idle": "2025-12-08T18:04:56.707231Z",
          "shell.execute_reply.started": "2025-12-08T18:04:56.699892Z",
          "shell.execute_reply": "2025-12-08T18:04:56.706524Z"
        },
        "id": "54b6661b-39c3-4a5e-93a8-6ebb96f9169b"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Loading and Fine Tuning"
      ],
      "metadata": {
        "id": "Z3kL8F3T-J-W"
      },
      "id": "Z3kL8F3T-J-W"
    },
    {
      "id": "6b6f4a56-1b17-419f-a5f8-cfe257679d5e",
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import torch\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "\n",
        "# Load model + tokenizer\n",
        "\n",
        "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\" #\"Qwen/Qwen3-0.6B\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    # torch_dtype=torch.float16,\n",
        "    # device_map=\"auto\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "model = base_model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "def preprocess(example):\n",
        "    q = example[\"question\"]\n",
        "    ans = example[\"answer\"]\n",
        "\n",
        "    build chat\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Question: {q}\"},\n",
        "        {\"role\": \"assistant\", \"content\": },\n",
        "    ]\n",
        "#     train_prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
        "# Write a response that appropriately completes the request.\n",
        "# Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
        "\n",
        "# ### Instruction:\n",
        "# You are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning.\n",
        "# Please answer the following medical question.\n",
        "\n",
        "# ### Question:\n",
        "# {}\n",
        "\n",
        "# ### Response:\n",
        "# <think>\n",
        "# {}\n",
        "# </think>\n",
        "# {}\"\"\"\n",
        "\n",
        "    # render chat into prompt\n",
        "    prompt = tokenizer.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=False\n",
        "    )\n",
        "\n",
        "    enc = tokenizer(prompt, truncation=True, max_length=512)\n",
        "\n",
        "    # mask labels so only assistant part contributes to loss\n",
        "    labels = enc[\"input_ids\"].copy()\n",
        "    assistant_start = prompt.index(ans)\n",
        "    tok_before_ans = tokenizer(prompt[:assistant_start], truncation=True, max_length=512)[\"input_ids\"]\n",
        "    labels[:len(tok_before_ans)] = [-100] * len(tok_before_ans)\n",
        "\n",
        "    enc[\"labels\"] = labels\n",
        "    return enc\n",
        "\n",
        "# processed_dataset = dataset.map(preprocess, remove_columns=dataset[\"train\"].column_names)\n",
        "\n",
        "\n",
        "\n",
        "# Tokenize datasets\n",
        "ds_train_tok = train_ds.map(preprocess, remove_columns=train_ds.column_names)\n",
        "ds_valid_tok = valid_ds.map(preprocess, remove_columns=valid_ds.column_names)\n",
        "\n",
        "# Set torch format\n",
        "ds_train_tok.set_format(\"torch\")\n",
        "ds_valid_tok.set_format(\"torch\")\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./qwen_phy_stack\",\n",
        "    save_total_limit=2,\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=8,\n",
        "    num_train_epochs=1,\n",
        "    learning_rate=2e-5,\n",
        "    logging_steps=500,\n",
        "    save_steps=1000,\n",
        "    fp16=True,\n",
        ")\n",
        "\n",
        "# works with causal LM too\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=tokenizer,\n",
        "    model=None,            # not needed here\n",
        "    padding=True,          # pad to longest in batch\n",
        "    max_length=512,\n",
        "    label_pad_token_id=-100\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=ds_train_tok,\n",
        "    eval_dataset=ds_valid_tok,\n",
        "    data_collator=data_collator,\n",
        "    callbacks=[WandbLimitedCheckpointCallback(project=\"qwen2.5_finetuning\", keep_last=2)]\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-08T18:04:56.708813Z",
          "iopub.execute_input": "2025-12-08T18:04:56.709246Z",
          "iopub.status.idle": "2025-12-08T19:09:34.932812Z",
          "shell.execute_reply.started": "2025-12-08T18:04:56.709226Z",
          "shell.execute_reply": "2025-12-08T19:09:34.932067Z"
        },
        "colab": {
          "referenced_widgets": [
            "0744f96b5b484b0d8ac47d8f714cca98",
            "ae1324fe59a14069a99e674976fdfdb2"
          ]
        },
        "id": "6b6f4a56-1b17-419f-a5f8-cfe257679d5e",
        "outputId": "f775e23c-758c-462c-e700-af3645326ba4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/15259 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0744f96b5b484b0d8ac47d8f714cca98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/3815 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae1324fe59a14069a99e674976fdfdb2"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py:741: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='954' max='954' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [954/954 1:03:51, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>2.430300</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./qwen_phy_stack/checkpoint-954)... Done. 35.5s\n",
          "output_type": "stream"
        },
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainOutput(global_step=954, training_loss=2.390531847811845, metrics={'train_runtime': 3835.7416, 'train_samples_per_second': 3.978, 'train_steps_per_second': 0.249, 'total_flos': 1.3447175487263232e+16, 'train_loss': 2.390531847811845, 'epoch': 1.0})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "id": "e3c893e4-8059-4923-984f-4eb010745b0a",
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# You already have ds_train_tok and ds_valid_tok\n",
        "train_loader = DataLoader(ds_train_tok, batch_size=2, shuffle=False, collate_fn=data_collator)\n",
        "valid_loader = DataLoader(ds_valid_tok, batch_size=2, shuffle=False, collate_fn=data_collator)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-08T19:09:34.936805Z",
          "iopub.execute_input": "2025-12-08T19:09:34.937062Z",
          "iopub.status.idle": "2025-12-08T19:09:34.941955Z",
          "shell.execute_reply.started": "2025-12-08T19:09:34.937043Z",
          "shell.execute_reply": "2025-12-08T19:09:34.941312Z"
        },
        "id": "e3c893e4-8059-4923-984f-4eb010745b0a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute BLEU and ROUGE Scores\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4lbRXzpM-VUS"
      },
      "id": "4lbRXzpM-VUS"
    },
    {
      "id": "421d2127-db49-4d1e-883e-86ab095dc3e5",
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def compute_perplexity(model, dataloader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_tokens = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            # number of valid tokens (labels != -100)\n",
        "            mask = batch[\"labels\"] != -100\n",
        "            num_tokens = mask.sum().item()\n",
        "\n",
        "            total_loss += (loss.item() * num_tokens)\n",
        "            total_tokens += num_tokens\n",
        "\n",
        "    avg_loss = total_loss / total_tokens\n",
        "    ppl = torch.exp(torch.tensor(avg_loss))\n",
        "    return ppl.item()\n",
        "\n",
        "train_ppl = compute_perplexity(model, train_loader, device)\n",
        "valid_ppl = compute_perplexity(model, valid_loader, device)\n",
        "\n",
        "print(f\"Train PPL: {train_ppl:.2f}\")\n",
        "print(f\"Valid PPL: {valid_ppl:.2f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-08T19:13:41.789559Z",
          "iopub.execute_input": "2025-12-08T19:13:41.789986Z",
          "iopub.status.idle": "2025-12-08T19:39:45.051090Z",
          "shell.execute_reply.started": "2025-12-08T19:13:41.789961Z",
          "shell.execute_reply": "2025-12-08T19:39:45.050112Z"
        },
        "id": "421d2127-db49-4d1e-883e-86ab095dc3e5",
        "outputId": "a0579ec1-52ed-4713-ec92-ca4c22ec9477"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "  0%|          | 0/7630 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n  warnings.warn(\n100%|██████████| 7630/7630 [20:49<00:00,  6.11it/s]\n100%|██████████| 1908/1908 [05:13<00:00,  6.08it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Train PPL: nan\nValid PPL: nan\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "id": "116982fd-35d7-48b8-b01b-cf69f1939206",
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "trusted": true,
        "id": "116982fd-35d7-48b8-b01b-cf69f1939206"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6b82f685-07b3-499e-97b2-dcf9ff257a6d",
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "print(datasets.__version__)\n",
        "import evaluate\n",
        "evaluate.__version__"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-08T20:14:54.854745Z",
          "iopub.execute_input": "2025-12-08T20:14:54.855548Z",
          "iopub.status.idle": "2025-12-08T20:14:54.863146Z",
          "shell.execute_reply.started": "2025-12-08T20:14:54.855522Z",
          "shell.execute_reply": "2025-12-08T20:14:54.862025Z"
        },
        "id": "6b82f685-07b3-499e-97b2-dcf9ff257a6d",
        "outputId": "bbb2cdcd-bc5f-417d-b0dc-28f4a216724b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "4.4.1\n",
          "output_type": "stream"
        },
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'0.4.6'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "id": "d22d44f4-31a9-4231-8710-84a718544071",
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "d22d44f4-31a9-4231-8710-84a718544071"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4cd7d5b2-7bf8-41b8-9c56-00c4aa883767",
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "\n",
        "bleu = load(\"bleu\")\n",
        "rouge = load(\"rouge\")\n",
        "\n",
        "def generate_predictions(model, dataset, device, max_new_tokens=128):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    refs = []\n",
        "    i = 0\n",
        "    for example in dataset:\n",
        "        input_ids = example[\"input_ids\"].unsqueeze(0).to(device)\n",
        "        attention_mask = example.get(\"attention_mask\", None)\n",
        "        if attention_mask is not None:\n",
        "            attention_mask = attention_mask.unsqueeze(0).to(device)\n",
        "\n",
        "        output_ids = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            # do_sample=False,   # deterministic greedy decoding\n",
        "        )\n",
        "\n",
        "        pred_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "        # reference text = the 'answer'\n",
        "        # ref_text = example[\"answer\"] if \"answer\" in example else tokenizer.decode(example[\"labels\"], skip_special_tokens=True)\n",
        "        if \"answer\" in example:\n",
        "            # Case 1: Use the original answer column if available (cleanest)\n",
        "            ref_text = example[\"answer\"]\n",
        "        else:\n",
        "            # Case 2: Decode the labels tensor (needs cleaning)\n",
        "            labels = example[\"labels\"]\n",
        "            valid_label_ids = labels[labels != -100]\n",
        "\n",
        "            ref_text = tokenizer.decode(\n",
        "                valid_label_ids.to('cpu').numpy(), # Move to CPU and convert to numpy array for decode\n",
        "                skip_special_tokens=True\n",
        "            )\n",
        "        print(i,\"Ref:\", ref_text)\n",
        "        print(\"Predicted:\", pred_text,\"\\n\\n\")\n",
        "        i+=1\n",
        "        preds.append(pred_text)\n",
        "        refs.append(ref_text)\n",
        "\n",
        "    return preds, refs\n",
        "\n",
        "# train_preds, train_refs = generate_predictions(model, ds_train_tok, device)\n",
        "print(len(ds_valid_tok))\n",
        "valid_preds, valid_refs = generate_predictions(model, ds_valid_tok, device)\n",
        "\n",
        "\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# BLEU expects list of tokenized references and predictions\n",
        "# train_bleu = corpus_bleu([[r.split()] for r in train_refs], [p.split() for p in train_preds])\n",
        "valid_bleu = corpus_bleu([[r.split()] for r in valid_refs], [p.split() for p in valid_preds])\n",
        "\n",
        "# print(f\"Train BLEU: {train_bleu*100:.2f}\")\n",
        "print(f\"Valid BLEU: {valid_bleu*100:.2f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "_kg_hide-output": true,
        "id": "4cd7d5b2-7bf8-41b8-9c56-00c4aa883767"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a23119a1-9a67-42ee-9eff-1be91aced22b",
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "rouge_metric = load(\"rouge\")\n",
        "\n",
        "# train_rouge = rouge_metric.compute(predictions=train_preds, references=train_refs)\n",
        "valid_rouge = rouge_metric.compute(predictions=valid_preds, references=valid_refs)\n",
        "\n",
        "# print(\"Train ROUGE:\", train_rouge)\n",
        "print(\"Valid ROUGE:\", valid_rouge)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-08T23:02:10.989263Z",
          "iopub.execute_input": "2025-12-08T23:02:10.989899Z",
          "iopub.status.idle": "2025-12-08T23:03:15.333872Z",
          "shell.execute_reply.started": "2025-12-08T23:02:10.989873Z",
          "shell.execute_reply": "2025-12-08T23:03:15.332962Z"
        },
        "id": "a23119a1-9a67-42ee-9eff-1be91aced22b",
        "outputId": "e5021220-5ce4-4dc1-9945-efec1aa6c4e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Valid ROUGE: {'rouge1': 0.6515035864155732, 'rouge2': 0.6498241928143722, 'rougeL': 0.6512615954820963, 'rougeLsum': 0.6512859395973}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "id": "5af3e6f3-3047-429d-8a39-4dd45c498ac9",
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "scores = {\n",
        "    \"Perplexity\": {\"Train\": train_ppl, \"Validation\": valid_ppl},\n",
        "    \"BLEU\": {#\"Train\": train_bleu*100,\n",
        "        \"Validation\": valid_bleu*100},\n",
        "    \"ROUGE-1\": {#\"Train\": train_rouge[\"rouge1\"].mid.fmeasure*100,\n",
        "        \"Validation\": valid_rouge[\"rouge1\"]*100},\n",
        "    \"ROUGE-2\": {#\"Train\": train_rouge[\"rouge2\"].mid.fmeasure*100,\n",
        "        \"Validation\": valid_rouge[\"rouge2\"]*100},\n",
        "    \"ROUGE-L\": {#\"Train\": train_rouge[\"rougeL\"].mid.fmeasure*100,\n",
        "        \"Validation\": valid_rouge[\"rougeL\"]*100},\n",
        "}\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "metrics = list(scores.keys())\n",
        "# train_vals = [scores[m][\"Train\"] for m in metrics]\n",
        "valid_vals = [scores[m][\"Validation\"] for m in metrics]\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "# rects1 = ax.bar(x - width/2, train_vals, width, label='Train')\n",
        "rects2 = ax.bar(x + width/2, valid_vals, width, label='Validation')\n",
        "\n",
        "ax.set_ylabel('Scores')\n",
        "ax.set_title('Train vs Validation Metrics')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend()\n",
        "\n",
        "# Add value labels\n",
        "for rect in rects2: #rects1 + rects2\n",
        "    height = rect.get_height()\n",
        "    ax.annotate(f'{height:.2f}',\n",
        "                xy=(rect.get_x() + rect.get_width()/2, height),\n",
        "                xytext=(0,3),\n",
        "                textcoords=\"offset points\",\n",
        "                ha='center', va='bottom')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-08T23:33:04.307195Z",
          "iopub.execute_input": "2025-12-08T23:33:04.307838Z",
          "iopub.status.idle": "2025-12-08T23:33:04.479518Z",
          "shell.execute_reply.started": "2025-12-08T23:33:04.307814Z",
          "shell.execute_reply": "2025-12-08T23:33:04.478674Z"
        },
        "id": "5af3e6f3-3047-429d-8a39-4dd45c498ac9",
        "outputId": "a6b423b4-e658-41ba-9e18-f8204ed07adb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1000x500 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "id": "d70a9fa8-ef76-4229-ac08-f8f8399c4ae9",
      "cell_type": "code",
      "source": [
        "scores['Perplexity']"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-08T23:01:14.115163Z",
          "iopub.execute_input": "2025-12-08T23:01:14.115712Z",
          "iopub.status.idle": "2025-12-08T23:01:14.121503Z",
          "shell.execute_reply.started": "2025-12-08T23:01:14.115689Z",
          "shell.execute_reply": "2025-12-08T23:01:14.120670Z"
        },
        "id": "d70a9fa8-ef76-4229-ac08-f8f8399c4ae9",
        "outputId": "8667dc73-4fde-4f71-83b1-00a5b134d2d4"
      },
      "outputs": [
        {
          "execution_count": 35,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'Train': nan, 'Validation': nan}"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "id": "0800f4c2-f3c3-4c65-9d38-cb58cf3be0ef",
      "cell_type": "raw",
      "source": [],
      "metadata": {
        "id": "0800f4c2-f3c3-4c65-9d38-cb58cf3be0ef"
      }
    },
    {
      "id": "23e91481-bf76-4d3e-ac45-c960c8e25ad0",
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "trusted": true,
        "id": "23e91481-bf76-4d3e-ac45-c960c8e25ad0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Summary:\n",
        "BLEU Score (Validation): The BLEU score for the validation set was 62.77%.\n",
        "ROUGE Scores (Validation): The ROUGE scores for the validation set were:\n",
        "        ROUGE-1: 65.15%\n",
        "        ROUGE-2: 64.98%\n",
        "        ROUGE-L: 65.13%\n",
        "\n",
        "The ROUGE scores (especially ROUGE-1 and ROUGE-L) and the BLEU score indicate a reasonably good performance in terms of overlap with the reference answers."
      ],
      "metadata": {
        "id": "aCVGBgCz-vBx"
      },
      "id": "aCVGBgCz-vBx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad8ddbdd"
      },
      "source": [
        "# References and Citations\n",
        "\n",
        "## Model\n",
        "*   **Qwen2.5-0.5B-Instruct**: The Qwen series of large language models are developed by Alibaba Cloud. For specific details and research papers related to Qwen models, you would typically refer to their official GitHub repository or associated publications by Alibaba Cloud. As of my last update, a general citation for the Qwen series would often point to their main project page or initial papers.\n",
        "    *   **Resource**: [Qwen GitHub Repository](https://github.com/QwenLM/Qwen)\n",
        "\n",
        "## Metrics\n",
        "*   **Perplexity**: A standard intrinsic evaluation metric for language models. It's inversely related to the probability of the test set given the language model. No specific paper is usually cited, but it's a fundamental concept in NLP.\n",
        "\n",
        "*   **BLEU (Bilingual Evaluation Understudy)**:\n",
        "    *   Papineni, K., Roukos, S., Ward, T., & Zhu, W. J. (2002, July). \"BLEU: a method for automatic evaluation of machine translation.\" In *Proceedings of the 40th annual meeting on Association for Computational Linguistics* (pp. 311-318).\n",
        "    *   **Resource**: [ACL Anthology](https://aclanthology.org/P02-1040/)\n",
        "\n",
        "*   **ROUGE (Recall-Oriented Understudy for Gisting Evaluation)**:\n",
        "    *   Lin, C. Y. (2004, July). \"ROUGE: A package for automatic evaluation of summaries.\" In *Text summarization branches out: Proceedings of the ACL-04 workshop* (pp. 74-81).\n",
        "    *   **Resource**: [ACL Anthology](https://aclanthology.org/W04-1013/)\n",
        "\n",
        "## Libraries and Tools\n",
        "*   **Hugging Face Transformers**: A widely used library for state-of-the-art Natural Language Processing. It provides thousands of pre-trained models to perform tasks on texts such as classification, information extraction, question answering, summarization, translation, text generation, etc.\n",
        "    *   Wolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., ... & Rush, A. M. (2020). \"Transformers: State-of-the-Art Natural Language Processing.\" In *Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations* (pp. 38-45).\n",
        "    *   **Resource**: [Hugging Face Transformers GitHub](https://github.com/huggingface/transformers)\n",
        "\n",
        "*   **Hugging Face Datasets**: A lightweight and extensible library to easily share and access datasets for Audio, Computer Vision, and Natural Language Processing (NLP).\n",
        "    *   Lhoest, Q., et al. (2021). \"Datasets: A Community Library for Research in NLP.\" In *Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations* (pp. 200-210).\n",
        "    *   **Resource**: [Hugging Face Datasets GitHub](https://github.com/huggingface/datasets)\n",
        "\n",
        "*   **Weights & Biases (W&B)**: A platform for machine learning experiment tracking, visualization, and collaboration.\n",
        "    *   **Resource**: [Weights & Biases Website](https://wandb.ai/)\n",
        "\n",
        "*   **PyTorch**: An open-source machine learning framework.\n",
        "    *   Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., ... & Chintala, S. (2019). \"PyTorch: An Imperative Style, High-Performance Deep Learning Library.\" In *Advances in Neural Information Processing Systems 32* (pp. 8024-8035).\n",
        "    *   **Resource**: [PyTorch Website](https://pytorch.org/)\n",
        "\n",
        "*   **Pandas**: A fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language.\n",
        "    *   McKinney, W. (2010). \"Data Structures for Statistical Computing in Python.\" In *Proceedings of the 9th Python in Science Conference* (Vol. 445, pp. 51-56).\n",
        "    *   **Resource**: [Pandas Website](https://pandas.pydata.org/)\n",
        "\n",
        "*   **NLTK (Natural Language Toolkit)**: A leading platform for building Python programs to work with human language data.\n",
        "    *   Bird, S., Klein, E., & Loper, E. (2009). *Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit*. O'Reilly Media.\n",
        "    *   **Resource**: [NLTK Website](https://www.nltk.org/)\n",
        "\n",
        "*   **Matplotlib**: A comprehensive library for creating static, animated, and interactive visualizations in Python.\n",
        "    *   Hunter, J. D. (2007). \"Matplotlib: A 2D Graphics Environment.\" *Computing in Science & Engineering*, *9*(3), 90-95.\n",
        "    *   **Resource**: [Matplotlib Website](https://matplotlib.org/)\n",
        "\n",
        "*   **Seaborn**: A Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.\n",
        "    *   Waskom, M. L. (2021). \"Seaborn: statistical data visualization.\" *Journal of Open Source Software*, *6*(60), 3021.\n",
        "    *   **Resource**: [Seaborn Website](https://seaborn.pydata.org/)\n",
        "\n",
        "*   **NumPy**: The fundamental package for numerical computing with Python.\n",
        "    *   Harris, C. R., Millman, K. J., van der Walt, S. J., Gommers, R., Virtanen, P., Cournapeau, D., ... & Oliphant, T. E. (2020). \"Array programming with NumPy.\" *Nature*, *585*(7825), 357-362.\n",
        "    *   **Resource**: [NumPy Website](https://numpy.org/)"
      ],
      "id": "ad8ddbdd"
    }
  ]
}